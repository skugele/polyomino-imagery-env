{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976690bc-ba87-4ecc-98a7-c18e751ee780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6786fa33-9113-42ab-8fa2-9fde22bee1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4fbc3-5d7f-409c-8af5-8d0a984d6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "import os\n",
    "\n",
    " # ----------------------------\n",
    " # Parsing function with standard python:\n",
    "\n",
    " def zip_data_parser(zip_fname):\n",
    "     os.system('unzip {0}'.format(zip_fname)) # unzip\n",
    "     folder_name = zip_fname.rsplit('.zip')[0]\n",
    "\n",
    "     # load data:\n",
    "     x_stack = []\n",
    "     y_stack = []\n",
    "     for i in range(n_images):\n",
    "         x_stack.append(misc.imread(folder_name + '/image-{0}.png'.format(i)))\n",
    "         y_stack.append(misc.imread(folder_name + '/mask-{0}.png'.format(i)))\n",
    "     x = np.array(x_stack)\n",
    "     y = np.array(y_stack)\n",
    "\n",
    "     os.system('rm -rf {0}'.format(folder_name)) # remove unzipped folder\n",
    "     return x, y \n",
    "\n",
    " # ----------------------------\n",
    " # Dataset pipeline:\n",
    "\n",
    " all_zip_paths = ['../data/'] # list of paths for each zip file\n",
    " train_data = tf.constant(all_zip_paths)\n",
    " train_data = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "\n",
    " train_data = train_data.map(\n",
    "            lambda filename: tf.py_func(  # Parse the record into tensors\n",
    "                zip_data_parser,\n",
    "                [filename],\n",
    "                [tf.float32, tf.float32]), num_parallel_calls=num_threads)\n",
    "\n",
    " # un-batch first, then batch the data again to have dimension [batch_size, N, M, C]\n",
    " train_data = train_data.apply(tf.data.experimental.unbatch())\n",
    " train_data = train_data.batch(b_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bbf034-1a8a-41a3-9680-1a945ad0b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "MNIST dataset loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...\\n')\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print('MNIST dataset loaded.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f2afd-ee8c-4588-bd18-36aa7d1e35fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32479a-9ede-4fd8-9708-d54b5456a932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6664e81-6261-40ef-afd6-52b848869206",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25302fb5-6d4d-4a94-8ffa-b4964650b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b289cb89-8766-4fa7-8fbc-f869c888f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b0024db-5b35-463a-9ded-97ffe4914041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.4426 - accuracy: 0.8755\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2481 - accuracy: 0.9295\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2100 - accuracy: 0.9396\n",
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Training model...\\n')\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=32)\n",
    "\n",
    "print('Model trained successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d5d0a-594b-468d-a248-1606b80f0356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyomino-imagery-env",
   "language": "python",
   "name": "polyomino-imagery-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
