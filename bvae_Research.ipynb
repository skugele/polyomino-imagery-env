{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1fiRxFY49EGBxnnBTyxBfN_w41OTd0r7P",
      "authorship_tag": "ABX9TyMO+VTxfi+LOwP7vrJd9sKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skugele/polyomino-imagery-env/blob/environment-additions/bvae_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VbZXSm7X4Haz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS\n",
        "INPUT_HEIGHT = 128\n",
        "INPUT_WIDTH = 128\n",
        "\n"
      ],
      "metadata": {
        "id": "ufEhEtAX4m-h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__(name=\"preprocessor\")\n",
        "    self.resizer = tf.keras.layers.Resizing(INPUT_HEIGHT, INPUT_WIDTH, name=f\"{self.name}_resizer\")\n",
        "    self.rescaler = tf.keras.layers.Rescaling(scale=1./255, name=f\"{self.name}_rescaler\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.rescaler(\n",
        "        self.resizer(inputs)\n",
        "    )"
      ],
      "metadata": {
        "id": "K8j2GNTi8pSR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Lambda, Reshape, Conv2DTranspose"
      ],
      "metadata": {
        "id": "CFkJYxeRCNNC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, latent_dims):\n",
        "    super().__init__(name=\"encoder\")\n",
        "\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    # layers\n",
        "    self.preprocess = Preprocessor()\n",
        "\n",
        "    self.conv1 = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', name='encoder_conv1')\n",
        "    self.mpool1 = MaxPool2D(name='encoder_mpool1')\n",
        "\n",
        "    self.conv2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', name='encoder_conv2')\n",
        "    self.mpool2 = MaxPool2D(name='encoder_mpool2')\n",
        "\n",
        "    self.conv3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu', name='encoder_conv3')\n",
        "    self.mpool3 = MaxPool2D(name='encoder_mpool3')\n",
        "\n",
        "    self.conv4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu', name='encoder_conv4')\n",
        "    self.mpool4 = MaxPool2D(name='encoder_mpool4')\n",
        "\n",
        "    self.flatten = Flatten(name='encoder_flatten')\n",
        "\n",
        "    self.logvar = Dense(self.latent_dims, name='encoder_logvar')\n",
        "    self.mu = Dense(self.latent_dims, name='encoder_mu')\n",
        "    self.sigma = Lambda(lambda x: tf.exp(0.5*x), name='encoder_sigma')\n",
        "\n",
        "  def encode(self, inputs, preprocess=True):\n",
        "    # print the shape of the input\n",
        "    # print(f\"Shape of input to encoder: {inputs.shape}\")\n",
        "    p = self.preprocess(inputs) if preprocess else inputs\n",
        "    x=self.conv1(p); x=self.mpool1(x)\n",
        "    x=self.conv2(x); x=self.mpool2(x)\n",
        "    x=self.conv3(x); x=self.mpool3(x)\n",
        "    x=self.conv4(x); x=self.mpool4(x)\n",
        "    x=self.flatten(x)\n",
        "    # print(f\"Shape of output from encoder: {x.shape}\")\n",
        "\n",
        "    return self.mu(x), self.logvar(x), self.sigma(self.logvar(x)), p\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.encode(inputs)\n",
        "\n",
        "  def summary(self, input_shape):\n",
        "    x = tf.keras.layers.Input(shape=input_shape)\n",
        "    model = tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "    return model.summary()\n"
      ],
      "metadata": {
        "id": "WKr2CVtE4sKY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, latent_dims):\n",
        "    super().__init__(name=\"decoder\")\n",
        "\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    # layers\n",
        "    self.dense1 = Dense(256 * 8 * 8, activation=\"relu\", name='decoder_dense1')\n",
        "    self.reshape1 = Reshape((8, 8, 256), name='decoder_reshape1')\n",
        "\n",
        "    self.conv1 = Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_conv1')\n",
        "    self.conv2 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_conv2')\n",
        "    self.conv3 = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_conv3')\n",
        "    self.conv4 = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_conv4')\n",
        "    self.conv5 = Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', name='decoder_conv5')\n",
        "\n",
        "  def decode(self, inputs):\n",
        "    # print the shape of the input\n",
        "    # print(f\"Shape of input to decoder: {inputs.shape}\")\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.reshape1(x)\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.conv5(x)\n",
        "    # print(f\"Shape of output from decoder: {x.shape}\")\n",
        "\n",
        "    return x\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.decode(inputs)\n",
        "\n",
        "  # def summary(self, input_shape):\n",
        "  #   x = tf.keras.layers.Input(shape=input_shape)\n",
        "  #   model = tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "  #   return model.summary()"
      ],
      "metadata": {
        "id": "SHWtLOBK4sYI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReconstructionLoss(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(ReconstructionLoss, self).__init__(name=\"reconstruction_loss\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs[0]\n",
        "    recon_x = inputs[1]\n",
        "\n",
        "    recon_loss = tf.reduce_sum(tf.keras.losses.binary_crossentropy(x, recon_x), axis=[1,2])\n",
        "    recon_loss = tf.reduce_mean(recon_loss)\n",
        "\n",
        "    self.add_loss(recon_loss)\n",
        "\n",
        "    return recon_loss"
      ],
      "metadata": {
        "id": "SnAxDQaRJBto"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KLLoss(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(KLLoss, self).__init__()\n",
        "\n",
        "    self.beta = tf.Variable(1.0, name=\"beta\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    mu = inputs[0]\n",
        "    logvar = inputs[1]\n",
        "\n",
        "    kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1)\n",
        "    kl_loss = kl_loss * self.beta\n",
        "\n",
        "    self.add_loss(kl_loss)\n",
        "    return kl_loss"
      ],
      "metadata": {
        "id": "_WMjd4MSJtyU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampler\n",
        "\n",
        "class Sampler(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__(name=\"sampler\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    mu = inputs[0]\n",
        "    sigma = inputs[1]\n",
        "\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "    epsilon = tf.random.normal(shape=(batch, dim))\n",
        "\n",
        "    # reparameterize\n",
        "    output =  mu + tf.multiply(sigma, epsilon)\n",
        "\n",
        "    # print(f\"Shape of output from sampler: {output.shape}\")\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "fni0MYfCTVqb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BVAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dims):\n",
        "    super().__init__(name=\"bvae\")\n",
        "\n",
        "    self.latent_dims = latent_dims\n",
        "\n",
        "    # layers\n",
        "    self.encoder = Encoder(self.latent_dims)\n",
        "    self.decoder = Decoder(self.latent_dims)\n",
        "\n",
        "    self.sampler = Sampler()\n",
        "\n",
        "    self.reconstruction_loss = ReconstructionLoss()\n",
        "    self.kl_loss = KLLoss()\n",
        "\n",
        "    # trackers\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "    self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "    self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    mu, logvar, sigma, x = self.encoder(inputs)\n",
        "    z = self.sampler([mu, sigma])\n",
        "    # print(f\"Shape of z: {z.shape}\")\n",
        "    recon_x = self.decoder(z)\n",
        "\n",
        "    kl_loss = self.kl_loss([mu, logvar])\n",
        "    reconstruction_loss = self.reconstruction_loss([x, recon_x])\n",
        "\n",
        "    return recon_x, kl_loss, reconstruction_loss\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "      return [\n",
        "          self.loss_tracker,\n",
        "          self.reconstruction_loss_tracker,\n",
        "          self.kl_loss_tracker,\n",
        "      ]\n",
        "\n",
        "  def train_step(self, data):\n",
        "    # print(f\"Shape of input data in train_step: {data.shape}\")\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      recon_x, kl_loss, reconstruction_loss = self(data)\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      # update the trackers\n",
        "      self.loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "      # gradients\n",
        "      grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    return {\n",
        "        m.name: m.result() for m in self.metrics\n",
        "    }\n",
        "\n",
        "  def test_step(self, data):\n",
        "    recon_x, kl_loss, reconstruction_loss = self(data)\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "    self.loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "    return {\n",
        "        m.name: m.result() for m in self.metrics\n",
        "    }\n",
        "\n",
        "  def encode(self, inputs, preprocess=True):\n",
        "    return self.encoder.encode(inputs, preprocess=preprocess)\n",
        "\n",
        "  def decode(self, inputs):\n",
        "    return self.decoder.decode(inputs)\n",
        "\n",
        "  def sample(self, mu, sigma):\n",
        "    return self.sampler([mu, sigma])\n",
        "\n",
        "  def calculate_reconstruction_loss(self, inputs):\n",
        "    return self.reconstruction_loss(inputs)\n",
        "\n",
        "  def calculate_kl_loss(self, inputs):\n",
        "    return self.kl_loss(inputs)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F_FyktKdUFCg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BetaVaeParameterUpdater(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, delta, limit):\n",
        "    super().__init__()\n",
        "    self.delta = delta\n",
        "    self.limit = limit\n",
        "\n",
        "  @tf.function\n",
        "  def update_beta(self):\n",
        "    beta = self.model.kl_loss.beta\n",
        "    beta.assign(tf.math.maximum(beta - self.delta, self.limit))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.update_beta()"
      ],
      "metadata": {
        "id": "dSr_E8Zfo2o3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"./images_flat.zip\"\n",
        "# unzip\n",
        "!unzip -q {file_path}"
      ],
      "metadata": {
        "id": "X8r2kl9jn9Nk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = \"./images/\"\n"
      ],
      "metadata": {
        "id": "VeQQPIaJokJ2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BVAE(latent_dims=8)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n"
      ],
      "metadata": {
        "id": "TtQhzkHDpUES"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view model summary\n",
        "model.encoder.summary((None, None, 1)) # Provide a valid input shape for the summary\n",
        "model.decoder.summary((None, None, 1)) # Provide a valid input shape for the summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KhEhxmx1qQ3l",
        "outputId": "8d483334-7f07-47fa-8cea-0d5bf9628b2e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input to encoder: (None, None, None, 1)\n",
            "Shape of output from encoder: (None, 16384)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ preprocessor        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPreprocessor\u001b[0m)      │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ preprocessor[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ encoder_conv1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ encoder_mpool1[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ encoder_conv2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ encoder_mpool2[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ encoder_conv3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ encoder_mpool3[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ encoder_conv4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_flatten     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ encoder_mpool4[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_logvar      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │    \u001b[38;5;34m131,080\u001b[0m │ encoder_flatten[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │ encoder_flatten[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mu (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │    \u001b[38;5;34m131,080\u001b[0m │ encoder_flatten[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_sigma       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ encoder_logvar[\u001b[38;5;34m1\u001b[0m… │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ preprocessor        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Preprocessor</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ preprocessor[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ encoder_mpool1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ encoder_mpool2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_conv3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_conv4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ encoder_mpool3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mpool4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_conv4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_flatten     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_mpool4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_logvar      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,080</span> │ encoder_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │ encoder_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_mu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,080</span> │ encoder_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_sigma       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_logvar[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m650,000\u001b[0m (2.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,000</span> (2.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m650,000\u001b[0m (2.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">650,000</span> (2.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input to decoder: (None, None, None, 1)\n",
            "Shape of output from decoder: (None, 128, 128, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_dense1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │        \u001b[38;5;34m32,768\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m16384\u001b[0m)                 │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_reshape1 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv1 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv2 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv3 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv4 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m18,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv5 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │           \u001b[38;5;34m289\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)                 │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_reshape1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder_conv5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,010,433\u001b[0m (3.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,433</span> (3.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,010,433\u001b[0m (3.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,433</span> (3.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = tf.keras.utils.image_dataset_from_directory(\n",
        "    images_path,\n",
        "    labels=None,\n",
        "    color_mode='grayscale',\n",
        "    image_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    shuffle=True, # Ensure shuffling for random split\n",
        "    seed=42 # Optional: Set seed for reproducible split\n",
        ")\n",
        "\n",
        "# Calculate the size of the dataset\n",
        "dataset_size = tf.data.experimental.cardinality(images).numpy()\n",
        "\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset using take and skip\n",
        "train_ds = images.take(train_size)\n",
        "test_ds = images.skip(train_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_i6G-LusZsS",
        "outputId": "4db3eb33-3218-4f2b-b686-e966c7eb85a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1899 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot part of the dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Take the first batch from the training dataset\n",
        "for batch in train_ds.take(1):\n",
        "    # The batch is a tensor of images\n",
        "    images_batch = batch\n",
        "\n",
        "# Select a few images from the batch to plot\n",
        "num_images_to_plot = 5\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(num_images_to_plot):\n",
        "    plt.subplot(1, num_images_to_plot, i + 1)\n",
        "    # Squeeze to remove the channel dimension for grayscale images if needed for plotting\n",
        "    plt.imshow(tf.squeeze(images_batch[i]).numpy(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Sample Training Images')\n",
        "plt.show()\n",
        "\n",
        "# Take the first batch from the testing dataset\n",
        "for batch in test_ds.take(1):\n",
        "    # The batch is a tensor of images\n",
        "    images_batch = batch\n",
        "\n",
        "# Select a few images from the batch to plot\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(num_images_to_plot):\n",
        "    plt.subplot(1, num_images_to_plot, i + 1)\n",
        "    # Squeeze to remove the channel dimension for grayscale images if needed for plotting\n",
        "    plt.imshow(tf.squeeze(images_batch[i]).numpy(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Sample Testing Images')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "cDXvvL1vtgEM",
        "outputId": "a46c175d-0f32-4f50-cecd-e58772f66445"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "beta_updater_callback = BetaVaeParameterUpdater(delta=0.01, limit=0.0) # Example values\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=1000, # Adjust the number of epochs as needed\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[beta_updater_callback] # Add the callback\n",
        ")\n",
        "\n",
        "# Plot training history (optional)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Ul0YsTt3I3",
        "outputId": "35b2773e-11dc-4a81-ce6e-cf9bfacf2b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - kl_loss: 14.2812 - loss: 3187.3901 - reconstruction_loss: 3173.1089 - val_kl_loss: 18.5514 - val_loss: 1839.6191 - val_reconstruction_loss: 1822.0776\n",
            "Epoch 2/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - kl_loss: 20.3096 - loss: 1759.5139 - reconstruction_loss: 1739.2042 - val_kl_loss: 22.3495 - val_loss: 1403.2627 - val_reconstruction_loss: 1390.9965\n",
            "Epoch 3/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - kl_loss: 19.6295 - loss: 1361.8145 - reconstruction_loss: 1342.1851 - val_kl_loss: 18.6595 - val_loss: 1242.8870 - val_reconstruction_loss: 1228.9518\n",
            "Epoch 4/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - kl_loss: 19.1035 - loss: 1283.2234 - reconstruction_loss: 1264.1199 - val_kl_loss: 22.8428 - val_loss: 1154.8669 - val_reconstruction_loss: 1134.7971\n",
            "Epoch 5/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 20.7613 - loss: 1120.8417 - reconstruction_loss: 1100.0806 - val_kl_loss: 20.3641 - val_loss: 1065.7878 - val_reconstruction_loss: 1049.1785\n",
            "Epoch 6/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - kl_loss: 19.3646 - loss: 1105.4563 - reconstruction_loss: 1086.0917 - val_kl_loss: 19.3122 - val_loss: 1091.2642 - val_reconstruction_loss: 1070.3419\n",
            "Epoch 7/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - kl_loss: 16.6961 - loss: 1272.5033 - reconstruction_loss: 1255.8074 - val_kl_loss: 24.3147 - val_loss: 1099.1337 - val_reconstruction_loss: 1071.9480\n",
            "Epoch 8/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - kl_loss: 24.1358 - loss: 1043.1851 - reconstruction_loss: 1019.0493 - val_kl_loss: 19.4836 - val_loss: 984.1716 - val_reconstruction_loss: 965.3645\n",
            "Epoch 9/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 18.2572 - loss: 1053.0643 - reconstruction_loss: 1034.8073 - val_kl_loss: 23.9654 - val_loss: 954.1378 - val_reconstruction_loss: 928.9731\n",
            "Epoch 10/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - kl_loss: 22.8918 - loss: 929.2382 - reconstruction_loss: 906.3463 - val_kl_loss: 22.0258 - val_loss: 886.8387 - val_reconstruction_loss: 865.4756\n",
            "Epoch 11/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 20.9117 - loss: 896.6589 - reconstruction_loss: 875.7473 - val_kl_loss: 19.5909 - val_loss: 849.1973 - val_reconstruction_loss: 832.2341\n",
            "Epoch 12/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 20.5400 - loss: 852.9072 - reconstruction_loss: 832.3672 - val_kl_loss: 22.5010 - val_loss: 813.5315 - val_reconstruction_loss: 791.4388\n",
            "Epoch 13/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 22.2315 - loss: 867.6055 - reconstruction_loss: 845.3741 - val_kl_loss: 22.9407 - val_loss: 987.4448 - val_reconstruction_loss: 962.2775\n",
            "Epoch 14/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 22.1617 - loss: 916.0797 - reconstruction_loss: 893.9181 - val_kl_loss: 20.9597 - val_loss: 859.9072 - val_reconstruction_loss: 836.7358\n",
            "Epoch 15/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 21.3620 - loss: 859.4333 - reconstruction_loss: 838.0714 - val_kl_loss: 17.8299 - val_loss: 927.1959 - val_reconstruction_loss: 897.3144\n",
            "Epoch 16/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 19.5516 - loss: 883.0160 - reconstruction_loss: 863.4644 - val_kl_loss: 17.6314 - val_loss: 1112.5131 - val_reconstruction_loss: 1100.2037\n",
            "Epoch 17/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 19.4721 - loss: 1068.8276 - reconstruction_loss: 1049.3555 - val_kl_loss: 29.5418 - val_loss: 934.5536 - val_reconstruction_loss: 902.3643\n",
            "Epoch 18/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 24.9349 - loss: 982.1101 - reconstruction_loss: 957.1752 - val_kl_loss: 17.7375 - val_loss: 1182.5605 - val_reconstruction_loss: 1167.4608\n",
            "Epoch 19/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 15.6646 - loss: 1387.6978 - reconstruction_loss: 1372.0333 - val_kl_loss: 24.0394 - val_loss: 959.1002 - val_reconstruction_loss: 935.1024\n",
            "Epoch 20/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 21.6072 - loss: 914.4120 - reconstruction_loss: 892.8048 - val_kl_loss: 20.8902 - val_loss: 948.3652 - val_reconstruction_loss: 932.6214\n",
            "Epoch 21/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - kl_loss: 22.4752 - loss: 868.2061 - reconstruction_loss: 845.7309 - val_kl_loss: 21.5506 - val_loss: 799.0165 - val_reconstruction_loss: 785.4070\n",
            "Epoch 22/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 20.5335 - loss: 775.1824 - reconstruction_loss: 754.6489 - val_kl_loss: 20.4504 - val_loss: 767.3660 - val_reconstruction_loss: 747.6525\n",
            "Epoch 23/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 20.4729 - loss: 744.8288 - reconstruction_loss: 724.3559 - val_kl_loss: 18.9659 - val_loss: 789.9973 - val_reconstruction_loss: 774.1343\n",
            "Epoch 24/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 19.3733 - loss: 759.7542 - reconstruction_loss: 740.3809 - val_kl_loss: 18.9441 - val_loss: 841.3448 - val_reconstruction_loss: 824.1075\n",
            "Epoch 25/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.7125 - loss: 762.7677 - reconstruction_loss: 744.0552 - val_kl_loss: 16.4019 - val_loss: 838.6902 - val_reconstruction_loss: 824.6577\n",
            "Epoch 26/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 17.0080 - loss: 802.4315 - reconstruction_loss: 785.4235 - val_kl_loss: 19.2358 - val_loss: 789.7504 - val_reconstruction_loss: 769.6443\n",
            "Epoch 27/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - kl_loss: 14.2434 - loss: 1119.7493 - reconstruction_loss: 1105.5060 - val_kl_loss: 29.3930 - val_loss: 1122.8820 - val_reconstruction_loss: 1092.5502\n",
            "Epoch 28/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 21.8755 - loss: 1030.3593 - reconstruction_loss: 1008.4835 - val_kl_loss: 20.4210 - val_loss: 818.0814 - val_reconstruction_loss: 797.9885\n",
            "Epoch 29/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 20.5652 - loss: 783.9255 - reconstruction_loss: 763.3603 - val_kl_loss: 19.6028 - val_loss: 732.0781 - val_reconstruction_loss: 712.2595\n",
            "Epoch 30/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.9456 - loss: 732.4271 - reconstruction_loss: 713.4815 - val_kl_loss: 17.6252 - val_loss: 762.7327 - val_reconstruction_loss: 750.2867\n",
            "Epoch 31/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.4238 - loss: 734.2322 - reconstruction_loss: 715.8083 - val_kl_loss: 18.8504 - val_loss: 721.3489 - val_reconstruction_loss: 699.5906\n",
            "Epoch 32/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - kl_loss: 18.6367 - loss: 678.5432 - reconstruction_loss: 659.9065 - val_kl_loss: 18.2409 - val_loss: 1150.7531 - val_reconstruction_loss: 1128.8866\n",
            "Epoch 33/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - kl_loss: 19.8425 - loss: 946.8455 - reconstruction_loss: 927.0030 - val_kl_loss: 20.0787 - val_loss: 745.8736 - val_reconstruction_loss: 729.2635\n",
            "Epoch 34/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.5795 - loss: 736.0486 - reconstruction_loss: 717.4691 - val_kl_loss: 16.0107 - val_loss: 1103.5004 - val_reconstruction_loss: 1081.8617\n",
            "Epoch 35/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 17.2543 - loss: 915.4232 - reconstruction_loss: 898.1689 - val_kl_loss: 18.3922 - val_loss: 741.2653 - val_reconstruction_loss: 724.5239\n",
            "Epoch 36/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.7202 - loss: 685.3603 - reconstruction_loss: 666.6401 - val_kl_loss: 18.6701 - val_loss: 677.2911 - val_reconstruction_loss: 668.8229\n",
            "Epoch 37/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 18.0878 - loss: 636.7901 - reconstruction_loss: 618.7023 - val_kl_loss: 17.3858 - val_loss: 659.4298 - val_reconstruction_loss: 643.4035\n",
            "Epoch 38/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - kl_loss: 17.6112 - loss: 623.1165 - reconstruction_loss: 605.5054 - val_kl_loss: 9.7973 - val_loss: 1191.8591 - val_reconstruction_loss: 1181.1475\n",
            "Epoch 39/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - kl_loss: 14.8993 - loss: 940.4809 - reconstruction_loss: 925.5815 - val_kl_loss: 15.9515 - val_loss: 802.4735 - val_reconstruction_loss: 792.8206\n",
            "Epoch 40/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 16.3391 - loss: 739.3004 - reconstruction_loss: 722.9614 - val_kl_loss: 16.3966 - val_loss: 665.0530 - val_reconstruction_loss: 645.0762\n",
            "Epoch 41/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 15.8902 - loss: 740.2399 - reconstruction_loss: 724.3497 - val_kl_loss: 17.1246 - val_loss: 650.1639 - val_reconstruction_loss: 637.5818\n",
            "Epoch 42/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 12.2639 - loss: 1428.5125 - reconstruction_loss: 1416.2484 - val_kl_loss: 17.8918 - val_loss: 745.3901 - val_reconstruction_loss: 723.7229\n",
            "Epoch 43/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - kl_loss: 17.6266 - loss: 695.4713 - reconstruction_loss: 677.8446 - val_kl_loss: 16.1873 - val_loss: 659.6443 - val_reconstruction_loss: 652.3251\n",
            "Epoch 44/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 15.8224 - loss: 658.0209 - reconstruction_loss: 642.1984 - val_kl_loss: 16.0870 - val_loss: 683.4930 - val_reconstruction_loss: 666.3441\n",
            "Epoch 45/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 16.2959 - loss: 649.9894 - reconstruction_loss: 633.6935 - val_kl_loss: 15.7188 - val_loss: 632.6741 - val_reconstruction_loss: 623.1849\n",
            "Epoch 46/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - kl_loss: 15.4801 - loss: 619.8613 - reconstruction_loss: 604.3812 - val_kl_loss: 16.2395 - val_loss: 667.6014 - val_reconstruction_loss: 653.1830\n",
            "Epoch 47/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - kl_loss: 15.5096 - loss: 729.9141 - reconstruction_loss: 714.4044 - val_kl_loss: 15.0266 - val_loss: 638.3492 - val_reconstruction_loss: 622.3672\n",
            "Epoch 48/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 14.8891 - loss: 631.2234 - reconstruction_loss: 616.3342 - val_kl_loss: 15.3286 - val_loss: 597.5010 - val_reconstruction_loss: 581.1970\n",
            "Epoch 49/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 14.9571 - loss: 579.4412 - reconstruction_loss: 564.4840 - val_kl_loss: 15.0831 - val_loss: 588.3422 - val_reconstruction_loss: 567.3887\n",
            "Epoch 50/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 14.5196 - loss: 579.7679 - reconstruction_loss: 565.2483 - val_kl_loss: 15.5337 - val_loss: 633.0610 - val_reconstruction_loss: 621.9767\n",
            "Epoch 51/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 12.8097 - loss: 690.8577 - reconstruction_loss: 678.0479 - val_kl_loss: 14.3997 - val_loss: 600.7688 - val_reconstruction_loss: 583.9226\n",
            "Epoch 52/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - kl_loss: 14.3599 - loss: 587.3156 - reconstruction_loss: 572.9557 - val_kl_loss: 12.8648 - val_loss: 846.4723 - val_reconstruction_loss: 841.2889\n",
            "Epoch 53/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 13.0415 - loss: 709.9395 - reconstruction_loss: 696.8981 - val_kl_loss: 14.5740 - val_loss: 635.6116 - val_reconstruction_loss: 625.4833\n",
            "Epoch 54/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 13.9864 - loss: 583.6991 - reconstruction_loss: 569.7126 - val_kl_loss: 12.9708 - val_loss: 602.7524 - val_reconstruction_loss: 593.2191\n",
            "Epoch 55/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 12.7710 - loss: 616.5839 - reconstruction_loss: 603.8130 - val_kl_loss: 13.0090 - val_loss: 596.0438 - val_reconstruction_loss: 583.1093\n",
            "Epoch 56/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 13.1557 - loss: 552.5013 - reconstruction_loss: 539.3456 - val_kl_loss: 13.5026 - val_loss: 541.8743 - val_reconstruction_loss: 535.3987\n",
            "Epoch 57/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 13.0971 - loss: 520.5293 - reconstruction_loss: 507.4323 - val_kl_loss: 13.0415 - val_loss: 519.2762 - val_reconstruction_loss: 507.9969\n",
            "Epoch 58/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - kl_loss: 12.9675 - loss: 485.9297 - reconstruction_loss: 472.9622 - val_kl_loss: 12.1610 - val_loss: 528.6995 - val_reconstruction_loss: 526.1230\n",
            "Epoch 59/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 11.9771 - loss: 514.9852 - reconstruction_loss: 503.0081 - val_kl_loss: 10.8909 - val_loss: 590.0899 - val_reconstruction_loss: 578.7433\n",
            "Epoch 60/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 11.1631 - loss: 570.3643 - reconstruction_loss: 559.2012 - val_kl_loss: 12.0883 - val_loss: 581.5533 - val_reconstruction_loss: 570.7032\n",
            "Epoch 61/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 11.9935 - loss: 522.9712 - reconstruction_loss: 510.9777 - val_kl_loss: 12.4842 - val_loss: 548.4529 - val_reconstruction_loss: 536.5162\n",
            "Epoch 62/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 11.7942 - loss: 532.7696 - reconstruction_loss: 520.9754 - val_kl_loss: 10.3867 - val_loss: 874.9753 - val_reconstruction_loss: 862.5453\n",
            "Epoch 63/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - kl_loss: 12.2379 - loss: 733.6219 - reconstruction_loss: 721.3841 - val_kl_loss: 12.5875 - val_loss: 581.4338 - val_reconstruction_loss: 568.6295\n",
            "Epoch 64/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - kl_loss: 12.4780 - loss: 534.2292 - reconstruction_loss: 521.7513 - val_kl_loss: 10.9390 - val_loss: 564.7916 - val_reconstruction_loss: 556.8079\n",
            "Epoch 65/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 10.6271 - loss: 561.3933 - reconstruction_loss: 550.7662 - val_kl_loss: 10.7562 - val_loss: 538.8910 - val_reconstruction_loss: 521.0600\n",
            "Epoch 66/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 10.6941 - loss: 525.9588 - reconstruction_loss: 515.2648 - val_kl_loss: 8.9431 - val_loss: 802.5862 - val_reconstruction_loss: 787.1039\n",
            "Epoch 67/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 10.8004 - loss: 687.9845 - reconstruction_loss: 677.1841 - val_kl_loss: 10.1620 - val_loss: 613.7485 - val_reconstruction_loss: 606.7829\n",
            "Epoch 68/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 10.8687 - loss: 538.1907 - reconstruction_loss: 527.3220 - val_kl_loss: 11.5392 - val_loss: 521.7162 - val_reconstruction_loss: 515.2975\n",
            "Epoch 69/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - kl_loss: 10.7499 - loss: 500.9150 - reconstruction_loss: 490.1652 - val_kl_loss: 10.4194 - val_loss: 596.4915 - val_reconstruction_loss: 579.6046\n",
            "Epoch 70/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 10.0074 - loss: 516.8729 - reconstruction_loss: 506.8655 - val_kl_loss: 9.4019 - val_loss: 634.6345 - val_reconstruction_loss: 615.8740\n",
            "Epoch 71/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 7.8523 - loss: 1338.3375 - reconstruction_loss: 1330.4851 - val_kl_loss: 10.6596 - val_loss: 937.2207 - val_reconstruction_loss: 921.1963\n",
            "Epoch 72/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 9.5877 - loss: 852.3459 - reconstruction_loss: 842.7584 - val_kl_loss: 8.4622 - val_loss: 740.4241 - val_reconstruction_loss: 730.0512\n",
            "Epoch 73/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 8.7682 - loss: 677.1331 - reconstruction_loss: 668.3649 - val_kl_loss: 13.1262 - val_loss: 861.1978 - val_reconstruction_loss: 852.4056\n",
            "Epoch 74/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - kl_loss: 11.7882 - loss: 744.6142 - reconstruction_loss: 732.8259 - val_kl_loss: 8.1355 - val_loss: 818.3356 - val_reconstruction_loss: 807.7014\n",
            "Epoch 75/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - kl_loss: 8.5753 - loss: 692.3880 - reconstruction_loss: 683.8126 - val_kl_loss: 9.3184 - val_loss: 611.8372 - val_reconstruction_loss: 597.5785\n",
            "Epoch 76/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 8.6984 - loss: 597.1552 - reconstruction_loss: 588.4567 - val_kl_loss: 3.7891 - val_loss: 2201.1055 - val_reconstruction_loss: 2183.5664\n",
            "Epoch 77/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 16.2851 - loss: 1717.1006 - reconstruction_loss: 1700.8157 - val_kl_loss: 20.5099 - val_loss: 882.5659 - val_reconstruction_loss: 857.9351\n",
            "Epoch 78/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 14.9957 - loss: 857.6082 - reconstruction_loss: 842.6125 - val_kl_loss: 12.3258 - val_loss: 748.1043 - val_reconstruction_loss: 741.4362\n",
            "Epoch 79/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 9.9013 - loss: 788.7554 - reconstruction_loss: 778.8541 - val_kl_loss: 9.0843 - val_loss: 774.0663 - val_reconstruction_loss: 763.7495\n",
            "Epoch 80/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 8.8791 - loss: 706.9631 - reconstruction_loss: 698.0840 - val_kl_loss: 9.0358 - val_loss: 635.2994 - val_reconstruction_loss: 619.6773\n",
            "Epoch 81/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - kl_loss: 8.1908 - loss: 620.7405 - reconstruction_loss: 612.5497 - val_kl_loss: 8.3887 - val_loss: 614.0192 - val_reconstruction_loss: 610.7544\n",
            "Epoch 82/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 7.9903 - loss: 567.6038 - reconstruction_loss: 559.6135 - val_kl_loss: 7.9240 - val_loss: 579.6565 - val_reconstruction_loss: 569.1284\n",
            "Epoch 83/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 6.9624 - loss: 531.6776 - reconstruction_loss: 524.7152 - val_kl_loss: 5.8051 - val_loss: 699.0885 - val_reconstruction_loss: 694.2586\n",
            "Epoch 84/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 5.9553 - loss: 677.1323 - reconstruction_loss: 671.1771 - val_kl_loss: 6.6479 - val_loss: 637.1439 - val_reconstruction_loss: 632.0314\n",
            "Epoch 85/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - kl_loss: 6.0360 - loss: 596.6852 - reconstruction_loss: 590.6492 - val_kl_loss: 5.7433 - val_loss: 592.8037 - val_reconstruction_loss: 585.5386\n",
            "Epoch 86/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 5.5066 - loss: 542.0050 - reconstruction_loss: 536.4984 - val_kl_loss: 5.5800 - val_loss: 543.4770 - val_reconstruction_loss: 540.7595\n",
            "Epoch 87/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 5.3109 - loss: 484.5575 - reconstruction_loss: 479.2466 - val_kl_loss: 5.0625 - val_loss: 511.7697 - val_reconstruction_loss: 508.9848\n",
            "Epoch 88/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - kl_loss: 4.8395 - loss: 479.9394 - reconstruction_loss: 475.0999 - val_kl_loss: 4.5222 - val_loss: 523.2130 - val_reconstruction_loss: 517.4517\n",
            "Epoch 89/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - kl_loss: 4.3960 - loss: 461.9418 - reconstruction_loss: 457.5458 - val_kl_loss: 4.5735 - val_loss: 484.5325 - val_reconstruction_loss: 477.6145\n",
            "Epoch 90/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 5.5079 - loss: 769.5015 - reconstruction_loss: 763.9935 - val_kl_loss: 18.5051 - val_loss: 1654.9156 - val_reconstruction_loss: 1631.3008\n",
            "Epoch 91/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - kl_loss: 14.4884 - loss: 1356.7468 - reconstruction_loss: 1342.2585 - val_kl_loss: 8.1362 - val_loss: 870.0395 - val_reconstruction_loss: 855.7917\n",
            "Epoch 92/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - kl_loss: 5.9228 - loss: 850.0795 - reconstruction_loss: 844.1568 - val_kl_loss: 4.2549 - val_loss: 816.3819 - val_reconstruction_loss: 808.8577\n",
            "Epoch 93/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 4.0791 - loss: 705.8120 - reconstruction_loss: 701.7328 - val_kl_loss: 4.0486 - val_loss: 621.0464 - val_reconstruction_loss: 614.6697\n",
            "Epoch 94/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 3.6254 - loss: 589.1393 - reconstruction_loss: 585.5138 - val_kl_loss: 3.6850 - val_loss: 601.0157 - val_reconstruction_loss: 602.8299\n",
            "Epoch 95/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 3.0276 - loss: 578.6818 - reconstruction_loss: 575.6541 - val_kl_loss: 3.0479 - val_loss: 634.9536 - val_reconstruction_loss: 642.0954\n",
            "Epoch 96/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 2.6936 - loss: 557.9667 - reconstruction_loss: 555.2731 - val_kl_loss: 2.4371 - val_loss: 536.9314 - val_reconstruction_loss: 536.9788\n",
            "Epoch 97/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - kl_loss: 2.0706 - loss: 486.2721 - reconstruction_loss: 484.2014 - val_kl_loss: 2.0174 - val_loss: 505.2141 - val_reconstruction_loss: 503.7874\n",
            "Epoch 98/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 1.5554 - loss: 506.6891 - reconstruction_loss: 505.1337 - val_kl_loss: 1.5630 - val_loss: 660.3285 - val_reconstruction_loss: 659.2673\n",
            "Epoch 99/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - kl_loss: 1.1203 - loss: 603.1213 - reconstruction_loss: 602.0011 - val_kl_loss: 0.9853 - val_loss: 602.1948 - val_reconstruction_loss: 593.5607\n",
            "Epoch 100/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.5314 - loss: 584.3133 - reconstruction_loss: 583.7819 - val_kl_loss: 0.5258 - val_loss: 617.7271 - val_reconstruction_loss: 615.3354\n",
            "Epoch 101/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 3.5680e-05 - loss: 550.0333 - reconstruction_loss: 550.0333 - val_kl_loss: 3.7184e-05 - val_loss: 578.8385 - val_reconstruction_loss: 576.5035\n",
            "Epoch 102/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 0.0000e+00 - loss: 581.0349 - reconstruction_loss: 581.0349 - val_kl_loss: 0.0000e+00 - val_loss: 517.7485 - val_reconstruction_loss: 526.6646\n",
            "Epoch 103/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 480.3047 - reconstruction_loss: 480.3047 - val_kl_loss: 0.0000e+00 - val_loss: 495.3401 - val_reconstruction_loss: 490.2818\n",
            "Epoch 104/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 458.9364 - reconstruction_loss: 458.9364 - val_kl_loss: 0.0000e+00 - val_loss: 495.0081 - val_reconstruction_loss: 492.1682\n",
            "Epoch 105/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 774.2990 - reconstruction_loss: 774.2990 - val_kl_loss: 0.0000e+00 - val_loss: 821.2631 - val_reconstruction_loss: 819.9910\n",
            "Epoch 106/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - kl_loss: 0.0000e+00 - loss: 731.8430 - reconstruction_loss: 731.8430 - val_kl_loss: 0.0000e+00 - val_loss: 681.1079 - val_reconstruction_loss: 684.4164\n",
            "Epoch 107/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 605.0878 - reconstruction_loss: 605.0878 - val_kl_loss: 0.0000e+00 - val_loss: 545.5006 - val_reconstruction_loss: 544.1910\n",
            "Epoch 108/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 521.6005 - reconstruction_loss: 521.6005 - val_kl_loss: 0.0000e+00 - val_loss: 516.8392 - val_reconstruction_loss: 515.4434\n",
            "Epoch 109/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 525.7397 - reconstruction_loss: 525.7397 - val_kl_loss: 0.0000e+00 - val_loss: 789.4482 - val_reconstruction_loss: 788.4434\n",
            "Epoch 110/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 688.9326 - reconstruction_loss: 688.9326 - val_kl_loss: 0.0000e+00 - val_loss: 707.1406 - val_reconstruction_loss: 701.2290\n",
            "Epoch 111/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 589.4548 - reconstruction_loss: 589.4548 - val_kl_loss: 0.0000e+00 - val_loss: 548.2413 - val_reconstruction_loss: 553.9276\n",
            "Epoch 112/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 0.0000e+00 - loss: 495.3394 - reconstruction_loss: 495.3394 - val_kl_loss: 0.0000e+00 - val_loss: 668.1060 - val_reconstruction_loss: 666.6821\n",
            "Epoch 113/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 0.0000e+00 - loss: 558.2552 - reconstruction_loss: 558.2552 - val_kl_loss: 0.0000e+00 - val_loss: 538.4277 - val_reconstruction_loss: 529.4178\n",
            "Epoch 114/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 562.2015 - reconstruction_loss: 562.2015 - val_kl_loss: 0.0000e+00 - val_loss: 556.5701 - val_reconstruction_loss: 553.6152\n",
            "Epoch 115/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 508.5997 - reconstruction_loss: 508.5997 - val_kl_loss: 0.0000e+00 - val_loss: 529.9806 - val_reconstruction_loss: 531.0508\n",
            "Epoch 116/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 471.4821 - reconstruction_loss: 471.4821 - val_kl_loss: 0.0000e+00 - val_loss: 478.5453 - val_reconstruction_loss: 488.2865\n",
            "Epoch 117/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - kl_loss: 0.0000e+00 - loss: 420.3027 - reconstruction_loss: 420.3027 - val_kl_loss: 0.0000e+00 - val_loss: 462.4767 - val_reconstruction_loss: 464.3553\n",
            "Epoch 118/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 408.6682 - reconstruction_loss: 408.6682 - val_kl_loss: 0.0000e+00 - val_loss: 738.5956 - val_reconstruction_loss: 738.7405\n",
            "Epoch 119/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 540.3123 - reconstruction_loss: 540.3123 - val_kl_loss: 0.0000e+00 - val_loss: 492.8041 - val_reconstruction_loss: 488.6803\n",
            "Epoch 120/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 428.5905 - reconstruction_loss: 428.5905 - val_kl_loss: 0.0000e+00 - val_loss: 506.3755 - val_reconstruction_loss: 504.7405\n",
            "Epoch 121/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 531.1559 - reconstruction_loss: 531.1559 - val_kl_loss: 0.0000e+00 - val_loss: 654.7852 - val_reconstruction_loss: 648.5201\n",
            "Epoch 122/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 594.7143 - reconstruction_loss: 594.7143 - val_kl_loss: 0.0000e+00 - val_loss: 544.0126 - val_reconstruction_loss: 549.2147\n",
            "Epoch 123/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - kl_loss: 0.0000e+00 - loss: 485.7378 - reconstruction_loss: 485.7378 - val_kl_loss: 0.0000e+00 - val_loss: 993.3207 - val_reconstruction_loss: 988.1926\n",
            "Epoch 124/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 747.5768 - reconstruction_loss: 747.5768 - val_kl_loss: 0.0000e+00 - val_loss: 589.0037 - val_reconstruction_loss: 588.2294\n",
            "Epoch 125/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 546.5300 - reconstruction_loss: 546.5300 - val_kl_loss: 0.0000e+00 - val_loss: 549.2687 - val_reconstruction_loss: 555.4404\n",
            "Epoch 126/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 484.1083 - reconstruction_loss: 484.1083 - val_kl_loss: 0.0000e+00 - val_loss: 487.6090 - val_reconstruction_loss: 481.6445\n",
            "Epoch 127/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 430.0203 - reconstruction_loss: 430.0203 - val_kl_loss: 0.0000e+00 - val_loss: 470.5701 - val_reconstruction_loss: 470.9131\n",
            "Epoch 128/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - kl_loss: 0.0000e+00 - loss: 488.4703 - reconstruction_loss: 488.4703 - val_kl_loss: 0.0000e+00 - val_loss: 542.5992 - val_reconstruction_loss: 541.1613\n",
            "Epoch 129/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 466.8406 - reconstruction_loss: 466.8406 - val_kl_loss: 0.0000e+00 - val_loss: 502.6497 - val_reconstruction_loss: 512.0450\n",
            "Epoch 130/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 436.0900 - reconstruction_loss: 436.0900 - val_kl_loss: 0.0000e+00 - val_loss: 451.3854 - val_reconstruction_loss: 451.6877\n",
            "Epoch 131/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 390.4892 - reconstruction_loss: 390.4892 - val_kl_loss: 0.0000e+00 - val_loss: 442.9611 - val_reconstruction_loss: 437.2759\n",
            "Epoch 132/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 0.0000e+00 - loss: 385.0876 - reconstruction_loss: 385.0876 - val_kl_loss: 0.0000e+00 - val_loss: 432.6773 - val_reconstruction_loss: 434.3402\n",
            "Epoch 133/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - kl_loss: 0.0000e+00 - loss: 382.2017 - reconstruction_loss: 382.2017 - val_kl_loss: 0.0000e+00 - val_loss: 507.7223 - val_reconstruction_loss: 506.6167\n",
            "Epoch 134/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - kl_loss: 0.0000e+00 - loss: 417.4269 - reconstruction_loss: 417.4269 - val_kl_loss: 0.0000e+00 - val_loss: 423.1637 - val_reconstruction_loss: 424.4317\n",
            "Epoch 135/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 353.3907 - reconstruction_loss: 353.3907 - val_kl_loss: 0.0000e+00 - val_loss: 409.9120 - val_reconstruction_loss: 406.2720\n",
            "Epoch 136/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 377.8707 - reconstruction_loss: 377.8707 - val_kl_loss: 0.0000e+00 - val_loss: 495.2067 - val_reconstruction_loss: 497.7192\n",
            "Epoch 137/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - kl_loss: 0.0000e+00 - loss: 412.9173 - reconstruction_loss: 412.9173 - val_kl_loss: 0.0000e+00 - val_loss: 539.8107 - val_reconstruction_loss: 532.7622\n",
            "Epoch 138/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 443.5015 - reconstruction_loss: 443.5015 - val_kl_loss: 0.0000e+00 - val_loss: 431.5336 - val_reconstruction_loss: 430.1012\n",
            "Epoch 139/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - kl_loss: 0.0000e+00 - loss: 372.0673 - reconstruction_loss: 372.0673 - val_kl_loss: 0.0000e+00 - val_loss: 1213.7250 - val_reconstruction_loss: 1208.4536\n",
            "Epoch 140/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - kl_loss: 0.0000e+00 - loss: 876.3971 - reconstruction_loss: 876.3971 - val_kl_loss: 0.0000e+00 - val_loss: 532.9880 - val_reconstruction_loss: 534.6581\n",
            "Epoch 141/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - kl_loss: 0.0000e+00 - loss: 471.6159 - reconstruction_loss: 471.6159 - val_kl_loss: 0.0000e+00 - val_loss: 476.8573 - val_reconstruction_loss: 475.4252\n",
            "Epoch 142/1000\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - kl_loss: 0.0000e+00 - loss: 415.1215 - reconstruction_loss: 415.1215 - val_kl_loss: 0.0000e+00 - val_loss: 494.7903 - val_reconstruction_loss: 497.4698\n",
            "Epoch 143/1000\n",
            "\u001b[1m47/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - kl_loss: 0.0000e+00 - loss: 434.5710 - reconstruction_loss: 434.5710"
          ]
        }
      ]
    }
  ]
}